{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('operations').getOrCreate()\n",
    "df = spark.read.csv('Untitled Folder/ChengduPM.csv', inferSchema=True, header=True)\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "  inputCols=['year',\n",
    "             'month',\n",
    "             'day',\n",
    "             'hour',\n",
    "             'season',\n",
    "             'DEWP',\n",
    "             'HUMI',\n",
    "             'PRES',\n",
    "             'TEMP',\n",
    "             'Iws',\n",
    "             'precipitation',\n",
    "             'Iprec',\n",
    "             'cbwd_new'],\n",
    "              outputCol=\"features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"Airlevel\", outputCol=\"AirlevelIndex\")\n",
    "output_fixed = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output_fixed.select(\"features\",'AirlevelIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing set.\n",
    "train_data,test_data = final_data.randomSplit([0.8,0.2])\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "dtc = DecisionTreeClassifier(labelCol='AirlevelIndex',featuresCol='features',\n",
    "                             impurity='entropy',maxBins=80,maxDepth=30)\n",
    "dtc_model = dtc.fit(train_data)\n",
    "dtc_predictions = dtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'AirlevelIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'AirlevelIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n"
     ]
    }
   ],
   "source": [
    "print(\"DTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.578953427851186\n",
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "|            features|AirlevelIndex|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "|[2013.0,1.0,1.0,1...|          4.0|[0.0,0.0,0.0,1.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,1.0,1.0,1...|          4.0|[0.0,25.0,0.0,0.0...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[2013.0,1.0,1.0,2...|          3.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|[2013.0,1.0,1.0,2...|          3.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|[2013.0,1.0,2.0,3...|          3.0|[0.0,0.0,0.0,1.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,1.0,2.0,5...|          4.0|[0.0,0.0,0.0,3.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,1.0,2.0,6...|          4.0|[0.0,0.0,0.0,3.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,1.0,2.0,1...|          4.0|[0.0,25.0,0.0,0.0...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[2013.0,1.0,2.0,2...|          0.0|[23.0,0.0,0.0,0.0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,1.0,3.0,1...|          0.0|[23.0,0.0,0.0,0.0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,1.0,3.0,1...|          1.0|[23.0,0.0,0.0,0.0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,1.0,4.0,1...|          4.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|[2013.0,1.0,4.0,1...|          3.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|[2013.0,1.0,4.0,2...|          0.0|[4.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,1.0,5.0,3...|          1.0|[0.0,0.0,0.0,19.0...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,1.0,5.0,5...|          1.0|[0.0,2.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[2013.0,1.0,5.0,1...|          4.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|[2013.0,1.0,5.0,1...|          1.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|[2013.0,1.0,5.0,1...|          1.0|[0.0,3.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[2013.0,1.0,5.0,1...|          4.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DTC\")\n",
    "print(my_binary_eval.evaluate(dtc_predictions))\n",
    "\n",
    "\n",
    "dtc_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# prediction1 = np.array(dtc_predictions.select('prediction').collect())\n",
    "# label = np.array(AirQualityIndex.select('AirQualityIndex').collect())\n",
    "\n",
    "results = dtc_predictions.select(['prediction', 'AirlevelIndex'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:249: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n",
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.6511907625691604\n",
      "F1 Score = 0.6511907625691604\n",
      "RFC\n",
      "0.5730449027758128\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)\n",
    "rfc = RandomForestClassifier(labelCol='AirlevelIndex',featuresCol='features',impurity='entropy'\n",
    "#                              ,maxBins=20,maxDepth=10\n",
    "                            )\n",
    "rfc_model = rfc.fit(train_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "# RFC improves accuracy but also model complexity. RFC outperforms DTC in nearly every situation.\n",
    "print(\"RFC\")\n",
    "print(my_binary_eval.evaluate(rfc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "|            features|AirlevelIndex|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "|[2013.0,1.0,1.0,1...|          4.0|[3.25815173840517...|[0.16290758692025...|       3.0|\n",
      "|[2013.0,1.0,1.0,1...|          4.0|[5.87494976905464...|[0.29374748845273...|       1.0|\n",
      "|[2013.0,1.0,1.0,2...|          3.0|[5.04062623808305...|[0.25203131190415...|       1.0|\n",
      "|[2013.0,1.0,1.0,2...|          3.0|[4.37276593746413...|[0.21863829687320...|       1.0|\n",
      "|[2013.0,1.0,2.0,3...|          3.0|[2.98400041844504...|[0.14920002092225...|       3.0|\n",
      "|[2013.0,1.0,2.0,5...|          4.0|[5.32397531864037...|[0.26619876593201...|       1.0|\n",
      "|[2013.0,1.0,2.0,6...|          4.0|[5.04062623808305...|[0.25203131190415...|       1.0|\n",
      "|[2013.0,1.0,2.0,1...|          4.0|[6.17401202190743...|[0.30870060109537...|       0.0|\n",
      "|[2013.0,1.0,2.0,2...|          0.0|[7.78657575362619...|[0.38932878768130...|       0.0|\n",
      "|[2013.0,1.0,3.0,1...|          0.0|[6.98626843951979...|[0.34931342197598...|       0.0|\n",
      "|[2013.0,1.0,3.0,1...|          1.0|[6.98626843951979...|[0.34931342197598...|       0.0|\n",
      "|[2013.0,1.0,4.0,1...|          4.0|[3.06226297076379...|[0.15311314853818...|       3.0|\n",
      "|[2013.0,1.0,4.0,1...|          3.0|[2.07743604529760...|[0.10387180226488...|       3.0|\n",
      "|[2013.0,1.0,4.0,2...|          0.0|[2.49230882279694...|[0.12461544113984...|       3.0|\n",
      "|[2013.0,1.0,5.0,3...|          1.0|[1.81752088785174...|[0.09087604439258...|       3.0|\n",
      "|[2013.0,1.0,5.0,5...|          1.0|[2.07743604529760...|[0.10387180226488...|       3.0|\n",
      "|[2013.0,1.0,5.0,1...|          4.0|[2.41709209773462...|[0.12085460488673...|       3.0|\n",
      "|[2013.0,1.0,5.0,1...|          1.0|[2.41709209773462...|[0.12085460488673...|       3.0|\n",
      "|[2013.0,1.0,5.0,1...|          1.0|[3.22645066308093...|[0.16132253315404...|       3.0|\n",
      "|[2013.0,1.0,5.0,1...|          4.0|[2.70795436065116...|[0.13539771803255...|       3.0|\n",
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- PM_US Post: integer (nullable = true)\n",
      " |-- DEWP: integer (nullable = true)\n",
      " |-- HUMI: double (nullable = true)\n",
      " |-- PRES: integer (nullable = true)\n",
      " |-- TEMP: integer (nullable = true)\n",
      " |-- cbwd: string (nullable = true)\n",
      " |-- Iws: integer (nullable = true)\n",
      " |-- precipitation: double (nullable = true)\n",
      " |-- Iprec: double (nullable = true)\n",
      " |-- Airlevel: integer (nullable = true)\n",
      " |-- cbwd_new: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.mllib.evaluation.MulticlassMetrics"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction1 = np.array(dtc_predictions.select('prediction').collect())\n",
    "# label = np.array(AirQualityIndex.select('AirQualityIndex').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rfc_predictions.select(['prediction', 'AirlevelIndex'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:249: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.4849651190762569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Recall = %s\" % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.4849651190762569\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score = %s\" % f1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
